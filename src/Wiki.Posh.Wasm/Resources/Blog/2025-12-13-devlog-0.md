---
title: Devlog 0 - The Introductening
tags: devlog
---

I'm about to find myself with a lot of free time on my paws. (I'm not getting fired, just my company is closing down for Christmas.) I kinda need something to do, instead of rotting in bed for 2 weeks, so I'm starting a personal project. Yay! 

I've had a lot of ideas for medium-sized projects. An IRC client, a native mobile client for booru-like sites, an SSH-based 2-system file manager, a text-to-speech app which can run natively and process long passages. Ultimately, though, I've landed on solving a problem that I face every day: organisation of massive numbers of files. 

I have a _lot_ of files. Like, I have 30TB attached to my main computer, hundreds of gigs of VPS, and probably a good couple of terabytes in physical media. Categorising them in a tree structure just doesn't suffice. 

<hr />

The thing that really pushed me into this idea was [Tag Studio](https://github.com/TagStudioDev/TagStudio), a cool FOSS project led by Travis "CyanVoxel" Abendshien. You can checkout his [devlogs](https://www.youtube.com/watch?v=x_x3FYfykgc) on YouTube. I'm also taking some inspiration from booru, specifically the implementations that make up [e926](https://e926.net/), which has a great search feature.

I've spent a few months thinking about this project, and how I want to do it. I've had a lot of time to think about which ideas are good and which are redundant, and how to properly architect the whole thing. Here are some of the core principles I've got going into it:

* I don't just want to tag files. The term I'm using for the object that will be tagged is a "resource", and they will be identified by a Uniform Resource Indicator (URI). 
* I want the possibility of performance at scale, which means using a fast language/runtime (C# and .NET) and keeping performance and memory profile in mind when performing operations. 
* I don't want to limit myself to one interface. I'll design a simple CLI, and architect in a way that leaves room for native apps, APIs, etc. My main focus will be on the core logic. 
* I don't want to limit myself to one database technology (a learning from TagStudio), so I'm going to use Entity Framework in the core to abstract over a range of implementations, and in the CLI, I'll interface with standard I/O rather than having my code be responsible for file I/O. 

To keep from the code becoming a mess, I'm separating my work into multiple loosely-defined phases, each of which will be written up as a new devlog post. These plans might undergo significant changes as I actually implement the thing, so take this with a league match of salt.

## Phase 1

Basic CRUD functionality for resources and tags. I'll have to create a database schema and basic commands to implement them. 

For the database, I'll need three tables: ResourceTable for resources, TagTable for tag definitions, and ResourceTagTable to link resources to tags. 
I'll create an index on both columns of ResourceTagTable to optimise lookups. 

For operations, the below table demonstrates basic commands' arguments will be typed, e.g. `x resource create <URI>`. The most difficult part of this will probably be parsing search queries. 

| x | Create | Read | Update | Delete | List |
|---|---|---|---|---|---|
| resource | URI | URI/GUID | URI/GUID add/remove ...tags | URI/GUID | EXPR |
| tag | name | name/GUID | name/GUID rename newName | name/GUID | REGEX |

I'll also add commands to `database import` and `database export` to easily save and load the database into a JSON format. 

## Phase 2

In phase 2, I'll expand functionality with implicit tags. I'll do this with a type called "implication", which will have a source tag and a target tag. Implications will be recursive, so, for example, if `[felis-catus]` implies `[felidae]` and `[felidae]` implies `[carnivora]`, then `[felis-catus]` implies `[carnivora]`. 

There'll be a new TagImplicationTable with columns ExplicitTagId and ImplicitTagId, indexed on ExplicitTagId. There'll also be a new set of commands: 

* `x implication create <explicit-tag> <implicit-tag>`
* `x implication list <explicit-tag>`
* `x implication delete <explicit-tag> <implicit-tag>`

I'll have to adjust the existing resource search command to consider implicit tags. They'll be visually separated when reading, to make it more difficult to mistake them for explicit tags. I'll also update `x resource update remove <...tags>`, where if a tag is not found to remove, we'll display a message showing which tag(s) caused it to be implicit on the resource. 

## Phase 3 

In phase 3, I'll expand functionality for tag grouping. The presence of certain tags will add certain "requirements" to a resource. 

A grouping requirement can be established if a resource has any of a set of tags. For example, grouping requirement `Dog Breed` could be triggered by any of [`[dog]`, `[canis-familiaris]`]. An empty list suggests that a grouping is a requirement for all resources. A requirement can then be satisfied by a list of pre-defined tags. Sticking with `Dog Breed`, it could be satisfied by adding `german-shepherd` or `golden-retriever`, but not `calico`. 

We'll need new tables TagGroupingRequirement (grouping), TagGroupingTrigger (grouping-trigger), and TagGroupingSatisfactor (grouping-satisfactor). We'll also need new commands to manage those types. 

Finally, we'll need a command to validate resources. It will look through each resource and load its implicit and explicit tags, then validate that all required groups are satisfied. Any resources with unsatisfied groups will be reported to the user. 

## Phase 4 

In phase 4, I'll add a key feature for managing duplicate data. I'll add an md5 checksum to the ResourceTable, and show warnings if the user tries to add an entry with a different URI but the same content as an existing resource. There will also be a command to re-check resources (by a certain filter), in case they change. 

The main challenge here will be deciding how to access resources, but I should be able to figure that out easily enough by reading the schema of the URI. Of course, I'll consider resources to be files if there's no schema given.

## Phase 5

In phase 5, I'll let users specify programs which can be used to access unfamiliar resources. As an example, a user could say that `tcp://*` should be retrieved using `/usr/sbin/curl`. 

## Future 

In the future, I'd like to add configurable vector encoding for text and images. Yes, I'm finally embracing machine learning. I'd expose a set list of ML models and let users configure which tags suggest which model's suitability. The major constraint of this is that since I'm using an ORM to abstract away the specific database implementation, remaining performant will be difficult. 
